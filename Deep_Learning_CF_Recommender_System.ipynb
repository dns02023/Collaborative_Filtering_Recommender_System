{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0            맛집              코드         닉네임  Unnamed: 0.1   평점  \\\n",
      "0              0          쭈불쭈불  Num=a_nam_0138      Abbbbb        3966.0  5.0   \n",
      "1              1          쭈불쭈불  Num=a_nam_0138        ^__^        3963.0  5.0   \n",
      "2              2          쭈불쭈불  Num=a_nam_0138    kookkook        3957.0  3.0   \n",
      "3              3          쭈불쭈불  Num=a_nam_0138       manbo        3968.0  4.0   \n",
      "4              4          쭈불쭈불  Num=a_nam_0138        검은여울        3961.0  4.0   \n",
      "...          ...           ...             ...         ...           ...  ...   \n",
      "6897        6897           제기집   Num=a_nam_927  lemondrop1        7196.0  5.0   \n",
      "6898        6898           제기집   Num=a_nam_927        직무유기        7197.0  5.0   \n",
      "6899        6899          테리키친   Num=a_nam_931        할거없넹        7557.0  5.0   \n",
      "6900        6900           홍릉각  Num=a_nam_1119         부처님        7350.0  5.0   \n",
      "6901        6901  황박사 통마늘오리주물럭  Num=a_nam_1109         씨제이        7580.0  5.0   \n",
      "\n",
      "      user_id  user_emb_id  place_id  place_emb_id  \n",
      "0           1            0         1             0  \n",
      "1           2            1         1             0  \n",
      "2           3            2         1             0  \n",
      "3           4            3         1             0  \n",
      "4           5            4         1             0  \n",
      "...       ...          ...       ...           ...  \n",
      "6897     2253         2252       407           406  \n",
      "6898     2254         2253       407           406  \n",
      "6899     2409         2408       408           407  \n",
      "6900     2497         2496       409           408  \n",
      "6901     2499         2498       410           409  \n",
      "\n",
      "[6902 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['Unnamed: 0'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                맛집              코드         닉네임  Unnamed: 0.1   평점  user_id  \\\n",
      "0             쭈불쭈불  Num=a_nam_0138      Abbbbb        3966.0  5.0        1   \n",
      "1             쭈불쭈불  Num=a_nam_0138        ^__^        3963.0  5.0        2   \n",
      "2             쭈불쭈불  Num=a_nam_0138    kookkook        3957.0  3.0        3   \n",
      "3             쭈불쭈불  Num=a_nam_0138       manbo        3968.0  4.0        4   \n",
      "4             쭈불쭈불  Num=a_nam_0138        검은여울        3961.0  4.0        5   \n",
      "...            ...             ...         ...           ...  ...      ...   \n",
      "6897           제기집   Num=a_nam_927  lemondrop1        7196.0  5.0     2253   \n",
      "6898           제기집   Num=a_nam_927        직무유기        7197.0  5.0     2254   \n",
      "6899          테리키친   Num=a_nam_931        할거없넹        7557.0  5.0     2409   \n",
      "6900           홍릉각  Num=a_nam_1119         부처님        7350.0  5.0     2497   \n",
      "6901  황박사 통마늘오리주물럭  Num=a_nam_1109         씨제이        7580.0  5.0     2499   \n",
      "\n",
      "      user_emb_id  place_id  place_emb_id  \n",
      "0               0         1             0  \n",
      "1               1         1             0  \n",
      "2               2         1             0  \n",
      "3               3         1             0  \n",
      "4               4         1             0  \n",
      "...           ...       ...           ...  \n",
      "6897         2252       407           406  \n",
      "6898         2253       407           406  \n",
      "6899         2408       408           407  \n",
      "6900         2496       409           408  \n",
      "6901         2498       410           409  \n",
      "\n",
      "[6902 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = ratings.pivot_table(index='user_emb_id', columns='코드', values='평점')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드           Num=a_nam_0001  Num=a_nam_0002  Num=a_nam_0003  Num=a_nam_0005  \\\n",
      "user_emb_id                                                                   \n",
      "0                       NaN             NaN             NaN             NaN   \n",
      "1                       NaN             5.0             NaN             5.0   \n",
      "2                       NaN             3.0             NaN             NaN   \n",
      "3                       NaN             4.0             NaN             NaN   \n",
      "4                       NaN             4.0             NaN             4.0   \n",
      "...                     ...             ...             ...             ...   \n",
      "2513                    NaN             NaN             NaN             NaN   \n",
      "2514                    NaN             NaN             NaN             NaN   \n",
      "2515                    NaN             NaN             NaN             NaN   \n",
      "2516                    NaN             NaN             NaN             NaN   \n",
      "2517                    NaN             NaN             NaN             NaN   \n",
      "\n",
      "코드           Num=a_nam_0007  Num=a_nam_0009  Num=a_nam_0010  Num=a_nam_0011  \\\n",
      "user_emb_id                                                                   \n",
      "0                       NaN             NaN             NaN             NaN   \n",
      "1                       NaN             NaN             NaN             NaN   \n",
      "2                       NaN             NaN             NaN             NaN   \n",
      "3                       NaN             NaN             NaN             NaN   \n",
      "4                       3.0             4.0             NaN             NaN   \n",
      "...                     ...             ...             ...             ...   \n",
      "2513                    NaN             NaN             NaN             NaN   \n",
      "2514                    NaN             NaN             NaN             NaN   \n",
      "2515                    NaN             NaN             NaN             NaN   \n",
      "2516                    NaN             NaN             NaN             NaN   \n",
      "2517                    NaN             NaN             NaN             NaN   \n",
      "\n",
      "코드           Num=a_nam_0013  Num=a_nam_0015  ...  Num=a_nam_964  \\\n",
      "user_emb_id                                  ...                  \n",
      "0                       NaN             NaN  ...            NaN   \n",
      "1                       NaN             NaN  ...            NaN   \n",
      "2                       NaN             NaN  ...            NaN   \n",
      "3                       NaN             NaN  ...            NaN   \n",
      "4                       NaN             NaN  ...            NaN   \n",
      "...                     ...             ...  ...            ...   \n",
      "2513                    NaN             NaN  ...            NaN   \n",
      "2514                    NaN             NaN  ...            NaN   \n",
      "2515                    NaN             NaN  ...            NaN   \n",
      "2516                    NaN             NaN  ...            NaN   \n",
      "2517                    NaN             NaN  ...            NaN   \n",
      "\n",
      "코드           Num=a_nam_969  Num=a_nam_972  Num=a_nam_974  Num=a_nam_978  \\\n",
      "user_emb_id                                                               \n",
      "0                      NaN            NaN            NaN            NaN   \n",
      "1                      NaN            NaN            NaN            NaN   \n",
      "2                      NaN            NaN            NaN            NaN   \n",
      "3                      NaN            NaN            NaN            NaN   \n",
      "4                      NaN            NaN            3.0            NaN   \n",
      "...                    ...            ...            ...            ...   \n",
      "2513                   NaN            NaN            NaN            NaN   \n",
      "2514                   NaN            NaN            NaN            NaN   \n",
      "2515                   NaN            NaN            NaN            NaN   \n",
      "2516                   5.0            NaN            NaN            NaN   \n",
      "2517                   NaN            NaN            NaN            NaN   \n",
      "\n",
      "코드           Num=a_nam_981  Num=a_nam_984  Num=a_nam_990  Num=a_nam_995  \\\n",
      "user_emb_id                                                               \n",
      "0                      NaN            NaN            NaN            NaN   \n",
      "1                      4.0            NaN            NaN            NaN   \n",
      "2                      3.0            NaN            NaN            NaN   \n",
      "3                      NaN            NaN            NaN            NaN   \n",
      "4                      5.0            NaN            NaN            NaN   \n",
      "...                    ...            ...            ...            ...   \n",
      "2513                   NaN            NaN            NaN            NaN   \n",
      "2514                   NaN            NaN            NaN            NaN   \n",
      "2515                   NaN            NaN            NaN            NaN   \n",
      "2516                   NaN            NaN            NaN            NaN   \n",
      "2517                   NaN            NaN            NaN            NaN   \n",
      "\n",
      "코드           Num=a_nam_996  \n",
      "user_emb_id                 \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "2                      NaN  \n",
      "3                      NaN  \n",
      "4                      5.0  \n",
      "...                    ...  \n",
      "2513                   NaN  \n",
      "2514                   NaN  \n",
      "2515                   NaN  \n",
      "2516                   NaN  \n",
      "2517                   NaN  \n",
      "\n",
      "[2518 rows x 410 columns]\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ratings = ratings.sample(frac=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         맛집              코드            닉네임  Unnamed: 0.1   평점  \\\n",
      "5159              감성밥집 도란도란   Num=a_nam_745        숑알숑알싸리잎        6681.0  3.0   \n",
      "6138                    투나스  Num=a_nam_0058        DrinkMe        6456.0  3.0   \n",
      "2729                  곰이네국밥   Num=a_nam_735         케익먹고싶다        1640.0  5.0   \n",
      "6234               향나무집 고대점  Num=a_nam_0077         I9C3G6        7405.0  4.0   \n",
      "2185                  고래돈까스  Num=a_nam_0247             소포        3387.0  4.0   \n",
      "...                     ...             ...            ...           ...  ...   \n",
      "263   ¸¾½ºÅÍÄ¡ Å¸ÀÌ°ÅÇÃ¶óÀÚ  Num=a_nam_0216        ewldndm        6266.0  5.0   \n",
      "5743                  핸썸베이글   Num=a_nam_727            컴포트        5427.0  4.0   \n",
      "6638                  로라방앗간   Num=a_nam_881          푹자고싶다        6837.0  4.0   \n",
      "6170                 마루가메제면  Num=a_nam_0360           돼지근육        5630.0  5.0   \n",
      "3587                    주유소  Num=a_nam_0157  brainstorming        1932.0  4.0   \n",
      "\n",
      "      user_id  user_emb_id  place_id  place_emb_id  \n",
      "5159      144          143       165           164  \n",
      "6138       86           85       246           245  \n",
      "2729     1069         1068        41            40  \n",
      "6234     1092         1091       255           254  \n",
      "2185       20           19        29            28  \n",
      "...       ...          ...       ...           ...  \n",
      "263       112          111         7             6  \n",
      "5743      263          262       207           206  \n",
      "6638     1440         1439       303           302  \n",
      "6170      168          167       250           249  \n",
      "3587      525          524        77            76  \n",
      "\n",
      "[6902 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 143   85 1068 ... 1439  167  524] (6902,)\n",
      "[164 245  40 ... 302 249  76] (6902,)\n",
      "[3. 3. 5. ... 4. 5. 4.] (6902,)\n"
     ]
    }
   ],
   "source": [
    "USERS = shuffled_ratings['user_emb_id'].values\n",
    "PLACES = shuffled_ratings['place_emb_id'].values\n",
    "#[USERS, PLACES] : input(X)\n",
    "RATINGS = shuffled_ratings['평점'].values\n",
    "# Y\n",
    "print(USERS, USERS.shape)\n",
    "print(PLACES, PLACES.shape)\n",
    "print(RATINGS, RATINGS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Embedding, Reshape, Merge\n",
    "from keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# user latent matrix와 item latent matrix를 각자의 embedding layer을 통해 학습한 후, merge layer에서 dot product 한다. \n",
    "class DLmodel(Sequential):\n",
    "\n",
    "    def __init__(self, n_users, m_items, k_factors, **kwargs):\n",
    "        P = Sequential()\n",
    "        P.add(Embedding(n_users, k_factors, input_length=1))\n",
    "        P.add(Reshape((k_factors,)))\n",
    "\n",
    "        Q = Sequential()\n",
    "        Q.add(Embedding(m_items, k_factors, input_length=1))\n",
    "        Q.add(Reshape((k_factors,)))\n",
    "\n",
    "        super(DLmodel, self).__init__(**kwargs)\n",
    "        self.add(Merge([P, Q], mode='dot', dot_axes=1))\n",
    "\n",
    "    def rate(self, user_id, item_id):\n",
    "        return self.predict([np.array([user_id]), np.array([item_id])])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2518, 410)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "max_placeid = ratings['place_id'].drop_duplicates().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518 410\n"
     ]
    }
   ],
   "source": [
    "print(max_userid, max_placeid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = CFModel(max_userid, max_placeid, 100)\n",
    "# model.compile(loss='mse', optimizer='adamax')\n",
    "#kfold 시에 주석처리 해야함(model을 for문 내에서 여러번 build함=>best model선정)\n",
    "#model = CFModel(max_userid, max_placeid, 100)\n",
    "#model.compile(loss='mse', optimizer='adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping('val_loss', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6211 samples, validate on 691 samples\n",
      "Epoch 1/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0625 - val_loss: 18.2511\n",
      "Epoch 2/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0554 - val_loss: 18.2501\n",
      "Epoch 3/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0455 - val_loss: 18.2467\n",
      "Epoch 4/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0288 - val_loss: 18.2390\n",
      "Epoch 5/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0020 - val_loss: 18.2245\n",
      "Epoch 6/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.9628 - val_loss: 18.2006\n",
      "Epoch 7/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.9086 - val_loss: 18.1654\n",
      "Epoch 8/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.8361 - val_loss: 18.1180\n",
      "Epoch 9/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.7453 - val_loss: 18.0579\n",
      "Epoch 10/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.6358 - val_loss: 17.9853\n",
      "Epoch 11/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.5068 - val_loss: 17.8981\n",
      "Epoch 12/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.3580 - val_loss: 17.7956\n",
      "Epoch 13/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.1860 - val_loss: 17.6775\n",
      "Epoch 14/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.9953 - val_loss: 17.5464\n",
      "Epoch 15/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.7866 - val_loss: 17.4032\n",
      "Epoch 16/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.5592 - val_loss: 17.2457\n",
      "Epoch 17/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.3121 - val_loss: 17.0748\n",
      "Epoch 18/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.0446 - val_loss: 16.8889\n",
      "Epoch 19/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.7590 - val_loss: 16.6895\n",
      "Epoch 20/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.4562 - val_loss: 16.4782\n",
      "Epoch 21/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.1409 - val_loss: 16.2589\n",
      "Epoch 22/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.8161 - val_loss: 16.0317\n",
      "Epoch 23/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.4782 - val_loss: 15.7963\n",
      "Epoch 24/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.1297 - val_loss: 15.5549\n",
      "Epoch 25/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.7798 - val_loss: 15.3138\n",
      "Epoch 26/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.4281 - val_loss: 15.0713\n",
      "Epoch 27/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.0760 - val_loss: 14.8319\n",
      "Epoch 28/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.7242 - val_loss: 14.5970\n",
      "Epoch 29/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.3774 - val_loss: 14.3681\n",
      "Epoch 30/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.0376 - val_loss: 14.1465\n",
      "Epoch 31/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.7060 - val_loss: 13.9325\n",
      "Epoch 32/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.3881 - val_loss: 13.7228\n",
      "Epoch 33/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.0792 - val_loss: 13.5211\n",
      "Epoch 34/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.7768 - val_loss: 13.3233\n",
      "Epoch 35/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.4835 - val_loss: 13.1296\n",
      "Epoch 36/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.1972 - val_loss: 12.9448\n",
      "Epoch 37/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.9188 - val_loss: 12.7640\n",
      "Epoch 38/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.6475 - val_loss: 12.5891\n",
      "Epoch 39/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.3827 - val_loss: 12.4211\n",
      "Epoch 40/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.1269 - val_loss: 12.2607\n",
      "Epoch 41/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.8803 - val_loss: 12.1062\n",
      "Epoch 42/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.6403 - val_loss: 11.9564\n",
      "Epoch 43/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.4106 - val_loss: 11.8098\n",
      "Epoch 44/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.1860 - val_loss: 11.6708\n",
      "Epoch 45/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.9673 - val_loss: 11.5358\n",
      "Epoch 46/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.7544 - val_loss: 11.4050\n",
      "Epoch 47/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.5463 - val_loss: 11.2790\n",
      "Epoch 48/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.3440 - val_loss: 11.1561\n",
      "Epoch 49/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.1458 - val_loss: 11.0367\n",
      "Epoch 50/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.9531 - val_loss: 10.9218\n",
      "Epoch 51/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.7691 - val_loss: 10.8105\n",
      "Epoch 52/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.5934 - val_loss: 10.7031\n",
      "Epoch 53/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.4238 - val_loss: 10.5996\n",
      "Epoch 54/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.2606 - val_loss: 10.4986\n",
      "Epoch 55/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.1039 - val_loss: 10.3996\n",
      "Epoch 56/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.9514 - val_loss: 10.3049\n",
      "Epoch 57/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.8040 - val_loss: 10.2150\n",
      "Epoch 58/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.6630 - val_loss: 10.1283\n",
      "Epoch 59/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.5264 - val_loss: 10.0438\n",
      "Epoch 60/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.3953 - val_loss: 9.9639\n",
      "Epoch 61/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.2684 - val_loss: 9.8850\n",
      "Epoch 62/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.1470 - val_loss: 9.8089\n",
      "Epoch 63/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.0283 - val_loss: 9.7347\n",
      "Epoch 64/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.9136 - val_loss: 9.6624\n",
      "Epoch 65/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.8024 - val_loss: 9.5945\n",
      "Epoch 66/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.6942 - val_loss: 9.5283\n",
      "Epoch 67/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.5893 - val_loss: 9.4654\n",
      "Epoch 68/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.4879 - val_loss: 9.4029\n",
      "Epoch 69/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.3892 - val_loss: 9.3418\n",
      "Epoch 70/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.2934 - val_loss: 9.2835\n",
      "Epoch 71/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.2001 - val_loss: 9.2254\n",
      "Epoch 72/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.1091 - val_loss: 9.1687\n",
      "Epoch 73/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.0204 - val_loss: 9.1146\n",
      "Epoch 74/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.9336 - val_loss: 9.0622\n",
      "Epoch 75/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.8495 - val_loss: 9.0105\n",
      "Epoch 76/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.7668 - val_loss: 8.9602\n",
      "Epoch 77/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.6861 - val_loss: 8.9119\n",
      "Epoch 78/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.6065 - val_loss: 8.8631\n",
      "Epoch 79/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.5291 - val_loss: 8.8168\n",
      "Epoch 80/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.4539 - val_loss: 8.7695\n",
      "Epoch 81/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.3806 - val_loss: 8.7242\n",
      "Epoch 82/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.3085 - val_loss: 8.6797\n",
      "Epoch 83/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.2381 - val_loss: 8.6352\n",
      "Epoch 84/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.1686 - val_loss: 8.5920\n",
      "Epoch 85/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.1010 - val_loss: 8.5526\n",
      "Epoch 86/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.0348 - val_loss: 8.5105\n",
      "Epoch 87/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.9699 - val_loss: 8.4719\n",
      "Epoch 88/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.9063 - val_loss: 8.4317\n",
      "Epoch 89/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.8441 - val_loss: 8.3942\n",
      "Epoch 90/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.7835 - val_loss: 8.3572\n",
      "Epoch 91/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.7240 - val_loss: 8.3221\n",
      "Epoch 92/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.6662 - val_loss: 8.2859\n",
      "Epoch 93/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.6099 - val_loss: 8.2527\n",
      "Epoch 94/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.5549 - val_loss: 8.2198\n",
      "Epoch 95/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.5013 - val_loss: 8.1874\n",
      "Epoch 96/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.4488 - val_loss: 8.1547\n",
      "Epoch 97/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.3975 - val_loss: 8.1260\n",
      "Epoch 98/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.3478 - val_loss: 8.0954\n",
      "Epoch 99/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.2991 - val_loss: 8.0682\n",
      "Epoch 100/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.2520 - val_loss: 8.0403\n",
      "Epoch 101/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.2057 - val_loss: 8.0149\n",
      "Epoch 102/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.1605 - val_loss: 7.9876\n",
      "Epoch 103/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.1161 - val_loss: 7.9612\n",
      "Epoch 104/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.0730 - val_loss: 7.9350\n",
      "Epoch 105/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.0308 - val_loss: 7.9108\n",
      "Epoch 106/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.9898 - val_loss: 7.8864\n",
      "Epoch 107/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.9498 - val_loss: 7.8643\n",
      "Epoch 108/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.9110 - val_loss: 7.8410\n",
      "Epoch 109/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.8733 - val_loss: 7.8196\n",
      "Epoch 110/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.8366 - val_loss: 7.7986\n",
      "Epoch 111/400\n",
      "6211/6211 [==============================] - ETA: 0s - loss: 1.782 - 0s - loss: 1.8005 - val_loss: 7.7796\n",
      "Epoch 112/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.7651 - val_loss: 7.7567\n",
      "Epoch 113/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.7307 - val_loss: 7.7383\n",
      "Epoch 114/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6972 - val_loss: 7.7192\n",
      "Epoch 115/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6646 - val_loss: 7.7009\n",
      "Epoch 116/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6326 - val_loss: 7.6821\n",
      "Epoch 117/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6016 - val_loss: 7.6648\n",
      "Epoch 118/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5711 - val_loss: 7.6481\n",
      "Epoch 119/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5417 - val_loss: 7.6328\n",
      "Epoch 120/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5127 - val_loss: 7.6149\n",
      "Epoch 121/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4843 - val_loss: 7.6001\n",
      "Epoch 122/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4566 - val_loss: 7.5851\n",
      "Epoch 123/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4295 - val_loss: 7.5716\n",
      "Epoch 124/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4031 - val_loss: 7.5543\n",
      "Epoch 125/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3773 - val_loss: 7.5425\n",
      "Epoch 126/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3521 - val_loss: 7.5270\n",
      "Epoch 127/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3280 - val_loss: 7.5140\n",
      "Epoch 128/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3037 - val_loss: 7.5000\n",
      "Epoch 129/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2805 - val_loss: 7.4894\n",
      "Epoch 130/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2575 - val_loss: 7.4752\n",
      "Epoch 131/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2354 - val_loss: 7.4642\n",
      "Epoch 132/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2138 - val_loss: 7.4533\n",
      "Epoch 133/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1926 - val_loss: 7.4422\n",
      "Epoch 134/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1719 - val_loss: 7.4294\n",
      "Epoch 135/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1514 - val_loss: 7.4184\n",
      "Epoch 136/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1316 - val_loss: 7.4075\n",
      "Epoch 137/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1126 - val_loss: 7.3969\n",
      "Epoch 138/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0936 - val_loss: 7.3871\n",
      "Epoch 139/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0752 - val_loss: 7.3779\n",
      "Epoch 140/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0570 - val_loss: 7.3667\n",
      "Epoch 141/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0396 - val_loss: 7.3576\n",
      "Epoch 142/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0224 - val_loss: 7.3474\n",
      "Epoch 143/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0058 - val_loss: 7.3391\n",
      "Epoch 144/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9895 - val_loss: 7.3273\n",
      "Epoch 145/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9736 - val_loss: 7.3219\n",
      "Epoch 146/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9580 - val_loss: 7.3114\n",
      "Epoch 147/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9425 - val_loss: 7.3055\n",
      "Epoch 148/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9275 - val_loss: 7.2966\n",
      "Epoch 149/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9128 - val_loss: 7.2909\n",
      "Epoch 150/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8986 - val_loss: 7.2825\n",
      "Epoch 151/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8844 - val_loss: 7.2757\n",
      "Epoch 152/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8707 - val_loss: 7.2659\n",
      "Epoch 153/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8574 - val_loss: 7.2609\n",
      "Epoch 154/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8440 - val_loss: 7.2531\n",
      "Epoch 155/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8311 - val_loss: 7.2483\n",
      "Epoch 156/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8186 - val_loss: 7.2391\n",
      "Epoch 157/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8062 - val_loss: 7.2345\n",
      "Epoch 158/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7941 - val_loss: 7.2285\n",
      "Epoch 159/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7824 - val_loss: 7.2236\n",
      "Epoch 160/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7710 - val_loss: 7.2177\n",
      "Epoch 161/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7598 - val_loss: 7.2128\n",
      "Epoch 162/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7485 - val_loss: 7.2063\n",
      "Epoch 163/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7380 - val_loss: 7.2029\n",
      "Epoch 164/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7273 - val_loss: 7.1976\n",
      "Epoch 165/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7172 - val_loss: 7.1938\n",
      "Epoch 166/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7069 - val_loss: 7.1901\n",
      "Epoch 167/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6970 - val_loss: 7.1843\n",
      "Epoch 168/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6872 - val_loss: 7.1796\n",
      "Epoch 169/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6777 - val_loss: 7.1764\n",
      "Epoch 170/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6211/6211 [==============================] - 0s - loss: 0.6684 - val_loss: 7.1720\n",
      "Epoch 171/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6595 - val_loss: 7.1680\n",
      "Epoch 172/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6507 - val_loss: 7.1645\n",
      "Epoch 173/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6419 - val_loss: 7.1609\n",
      "Epoch 174/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6335 - val_loss: 7.1557\n",
      "Epoch 175/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6252 - val_loss: 7.1548\n",
      "Epoch 176/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6169 - val_loss: 7.1483\n",
      "Epoch 177/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6091 - val_loss: 7.1476\n",
      "Epoch 178/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6013 - val_loss: 7.1418\n",
      "Epoch 179/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5936 - val_loss: 7.1415\n",
      "Epoch 180/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5862 - val_loss: 7.1354\n",
      "Epoch 181/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5789 - val_loss: 7.1359\n",
      "Epoch 182/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5717 - val_loss: 7.1293\n",
      "Epoch 183/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5645 - val_loss: 7.1285\n",
      "Epoch 184/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5577 - val_loss: 7.1242\n",
      "Epoch 185/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5512 - val_loss: 7.1236\n",
      "Epoch 186/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5447 - val_loss: 7.1179\n",
      "Epoch 187/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5381 - val_loss: 7.1196\n",
      "Epoch 188/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5319 - val_loss: 7.1142\n",
      "Epoch 189/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5256 - val_loss: 7.1136\n",
      "Epoch 190/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5198 - val_loss: 7.1089\n",
      "Epoch 191/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5137 - val_loss: 7.1091\n",
      "Epoch 192/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5081 - val_loss: 7.1060\n",
      "Epoch 193/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5024 - val_loss: 7.1063\n",
      "Epoch 194/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4969 - val_loss: 7.1008\n",
      "Epoch 195/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4914 - val_loss: 7.1012\n",
      "Epoch 196/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4862 - val_loss: 7.0986\n",
      "Epoch 197/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4810 - val_loss: 7.0981\n",
      "Epoch 198/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4759 - val_loss: 7.0939\n",
      "Epoch 199/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4709 - val_loss: 7.0947\n",
      "Epoch 200/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4659 - val_loss: 7.0910\n",
      "Epoch 201/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4611 - val_loss: 7.0912\n",
      "Epoch 202/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4565 - val_loss: 7.0874\n",
      "Epoch 203/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4517 - val_loss: 7.0887\n",
      "Epoch 204/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4473 - val_loss: 7.0845\n",
      "Epoch 205/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4428 - val_loss: 7.0851\n",
      "Epoch 206/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4383 - val_loss: 7.0829\n",
      "Epoch 207/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4340 - val_loss: 7.0830\n",
      "Epoch 208/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4298 - val_loss: 7.0813\n",
      "Epoch 209/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4255 - val_loss: 7.0822\n",
      "Epoch 210/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4215 - val_loss: 7.0782\n",
      "Epoch 211/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4173 - val_loss: 7.0797\n",
      "Epoch 212/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4134 - val_loss: 7.0764\n",
      "Epoch 213/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4095 - val_loss: 7.0781\n",
      "Epoch 214/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4058 - val_loss: 7.0739\n",
      "Epoch 215/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4019 - val_loss: 7.0766\n",
      "Epoch 216/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3981 - val_loss: 7.0726\n",
      "Epoch 217/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3946 - val_loss: 7.0764\n",
      "Epoch 218/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3909 - val_loss: 7.0711\n",
      "Epoch 219/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3875 - val_loss: 7.0746\n",
      "Epoch 220/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3839 - val_loss: 7.0703\n",
      "Epoch 221/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3806 - val_loss: 7.0736\n",
      "Epoch 222/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3771 - val_loss: 7.0697\n",
      "Epoch 223/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3739 - val_loss: 7.0722\n",
      "Epoch 224/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3706 - val_loss: 7.0695\n",
      "Epoch 225/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3673 - val_loss: 7.0707\n",
      "Epoch 226/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3641 - val_loss: 7.0672\n",
      "Epoch 227/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3610 - val_loss: 7.0701\n",
      "Epoch 228/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3579 - val_loss: 7.0656\n",
      "Epoch 229/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3548 - val_loss: 7.0689\n",
      "Epoch 230/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3518 - val_loss: 7.0644\n",
      "Epoch 231/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3489 - val_loss: 7.0661\n",
      "Epoch 232/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3459 - val_loss: 7.0648\n",
      "Epoch 233/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.3430 - val_loss: 7.0673\n",
      " 32/691 [>.............................] - ETA: 0sTrain on 6211 samples, validate on 691 samples\n",
      "Epoch 1/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0587 - val_loss: 18.2852\n",
      "Epoch 2/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0508 - val_loss: 18.2833\n",
      "Epoch 3/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0388 - val_loss: 18.2773\n",
      "Epoch 4/400\n",
      "6211/6211 [==============================] - 0s - loss: 18.0167 - val_loss: 18.2636\n",
      "Epoch 5/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.9795 - val_loss: 18.2394\n",
      "Epoch 6/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.9263 - val_loss: 18.2042\n",
      "Epoch 7/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.8546 - val_loss: 18.1556\n",
      "Epoch 8/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.7622 - val_loss: 18.0925\n",
      "Epoch 9/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.6491 - val_loss: 18.0135\n",
      "Epoch 10/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.5143 - val_loss: 17.9194\n",
      "Epoch 11/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.3567 - val_loss: 17.8075\n",
      "Epoch 12/400\n",
      "6211/6211 [==============================] - 0s - loss: 17.1779 - val_loss: 17.6791\n",
      "Epoch 13/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.9742 - val_loss: 17.5331\n",
      "Epoch 14/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.7441 - val_loss: 17.3696\n",
      "Epoch 15/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.4925 - val_loss: 17.1932\n",
      "Epoch 16/400\n",
      "6211/6211 [==============================] - 0s - loss: 16.2218 - val_loss: 16.9996\n",
      "Epoch 17/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.9314 - val_loss: 16.7904\n",
      "Epoch 18/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.6203 - val_loss: 16.5661\n",
      "Epoch 19/400\n",
      "6211/6211 [==============================] - 0s - loss: 15.2895 - val_loss: 16.3318\n",
      "Epoch 20/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.9426 - val_loss: 16.0816\n",
      "Epoch 21/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.5801 - val_loss: 15.8209\n",
      "Epoch 22/400\n",
      "6211/6211 [==============================] - 0s - loss: 14.2110 - val_loss: 15.5551\n",
      "Epoch 23/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.8352 - val_loss: 15.2840\n",
      "Epoch 24/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.4577 - val_loss: 15.0108\n",
      "Epoch 25/400\n",
      "6211/6211 [==============================] - 0s - loss: 13.0825 - val_loss: 14.7411\n",
      "Epoch 26/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.7151 - val_loss: 14.4775\n",
      "Epoch 27/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.3571 - val_loss: 14.2236\n",
      "Epoch 28/400\n",
      "6211/6211 [==============================] - 0s - loss: 12.0075 - val_loss: 13.9752\n",
      "Epoch 29/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.6701 - val_loss: 13.7367\n",
      "Epoch 30/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.3448 - val_loss: 13.5090\n",
      "Epoch 31/400\n",
      "6211/6211 [==============================] - 0s - loss: 11.0280 - val_loss: 13.2887\n",
      "Epoch 32/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.7198 - val_loss: 13.0808\n",
      "Epoch 33/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.4216 - val_loss: 12.8822\n",
      "Epoch 34/400\n",
      "6211/6211 [==============================] - 0s - loss: 10.1309 - val_loss: 12.6908\n",
      "Epoch 35/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.8474 - val_loss: 12.5089\n",
      "Epoch 36/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.5733 - val_loss: 12.3369\n",
      "Epoch 37/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.3097 - val_loss: 12.1730\n",
      "Epoch 38/400\n",
      "6211/6211 [==============================] - 0s - loss: 9.0525 - val_loss: 12.0165\n",
      "Epoch 39/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.8060 - val_loss: 11.8691\n",
      "Epoch 40/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.5714 - val_loss: 11.7291\n",
      "Epoch 41/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.3461 - val_loss: 11.5953\n",
      "Epoch 42/400\n",
      "6211/6211 [==============================] - 0s - loss: 8.1290 - val_loss: 11.4671\n",
      "Epoch 43/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.9164 - val_loss: 11.3429\n",
      "Epoch 44/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.7092 - val_loss: 11.2237\n",
      "Epoch 45/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.5085 - val_loss: 11.1095\n",
      "Epoch 46/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.3132 - val_loss: 10.9997\n",
      "Epoch 47/400\n",
      "6211/6211 [==============================] - 0s - loss: 7.1235 - val_loss: 10.8920\n",
      "Epoch 48/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.9395 - val_loss: 10.7894\n",
      "Epoch 49/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.7620 - val_loss: 10.6884s: \n",
      "Epoch 50/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.5899 - val_loss: 10.5872\n",
      "Epoch 51/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.4235 - val_loss: 10.4902\n",
      "Epoch 52/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.2633 - val_loss: 10.3978\n",
      "Epoch 53/400\n",
      "6211/6211 [==============================] - 0s - loss: 6.1078 - val_loss: 10.3073\n",
      "Epoch 54/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.9569 - val_loss: 10.2178\n",
      "Epoch 55/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.8116 - val_loss: 10.1286\n",
      "Epoch 56/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.6708 - val_loss: 10.0455\n",
      "Epoch 57/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.5355 - val_loss: 9.9648\n",
      "Epoch 58/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.4051 - val_loss: 9.8862\n",
      "Epoch 59/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.2793 - val_loss: 9.8092\n",
      "Epoch 60/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.1580 - val_loss: 9.7355\n",
      "Epoch 61/400\n",
      "6211/6211 [==============================] - 0s - loss: 5.0410 - val_loss: 9.6632\n",
      "Epoch 62/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.9268 - val_loss: 9.5909\n",
      "Epoch 63/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.8168 - val_loss: 9.5219\n",
      "Epoch 64/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.7097 - val_loss: 9.4534\n",
      "Epoch 65/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.6050 - val_loss: 9.3867\n",
      "Epoch 66/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.5025 - val_loss: 9.3207\n",
      "Epoch 67/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.4024 - val_loss: 9.2572\n",
      "Epoch 68/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.3058 - val_loss: 9.1959\n",
      "Epoch 69/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.2113 - val_loss: 9.1363\n",
      "Epoch 70/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.1200 - val_loss: 9.0796\n",
      "Epoch 71/400\n",
      "6211/6211 [==============================] - 0s - loss: 4.0314 - val_loss: 9.0239\n",
      "Epoch 72/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.9450 - val_loss: 8.9703\n",
      "Epoch 73/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.8613 - val_loss: 8.9168\n",
      "Epoch 74/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.7791 - val_loss: 8.8642\n",
      "Epoch 75/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.6982 - val_loss: 8.8134\n",
      "Epoch 76/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.6198 - val_loss: 8.7648\n",
      "Epoch 77/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.5434 - val_loss: 8.7163\n",
      "Epoch 78/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.4691 - val_loss: 8.6703\n",
      "Epoch 79/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.3965 - val_loss: 8.6241\n",
      "Epoch 80/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.3254 - val_loss: 8.5802\n",
      "Epoch 81/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.2564 - val_loss: 8.5369\n",
      "Epoch 82/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.1890 - val_loss: 8.4960\n",
      "Epoch 83/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.1232 - val_loss: 8.4553\n",
      "Epoch 84/400\n",
      "6211/6211 [==============================] - 0s - loss: 3.0586 - val_loss: 8.4168\n",
      "Epoch 85/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.9952 - val_loss: 8.3778\n",
      "Epoch 86/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.9332 - val_loss: 8.3402\n",
      "Epoch 87/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.8722 - val_loss: 8.3045\n",
      "Epoch 88/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.8123 - val_loss: 8.2708\n",
      "Epoch 89/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.7545 - val_loss: 8.2371\n",
      "Epoch 90/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.6979 - val_loss: 8.2050\n",
      "Epoch 91/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.6425 - val_loss: 8.1726\n",
      "Epoch 92/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.5880 - val_loss: 8.1433\n",
      "Epoch 93/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.5350 - val_loss: 8.1142\n",
      "Epoch 94/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.4833 - val_loss: 8.0856\n",
      "Epoch 95/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.4327 - val_loss: 8.0559\n",
      "Epoch 96/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.3834 - val_loss: 8.0305\n",
      "Epoch 97/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.3356 - val_loss: 8.0039\n",
      "Epoch 98/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.2892 - val_loss: 7.9800\n",
      "Epoch 99/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.2439 - val_loss: 7.9543\n",
      "Epoch 100/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.1997 - val_loss: 7.9313\n",
      "Epoch 101/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.1567 - val_loss: 7.9082\n",
      "Epoch 102/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.1145 - val_loss: 7.8861\n",
      "Epoch 103/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.0731 - val_loss: 7.8642\n",
      "Epoch 104/400\n",
      "6211/6211 [==============================] - 0s - loss: 2.0330 - val_loss: 7.8439\n",
      "Epoch 105/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.9933 - val_loss: 7.8230\n",
      "Epoch 106/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6211/6211 [==============================] - 0s - loss: 1.9549 - val_loss: 7.8032\n",
      "Epoch 107/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.9174 - val_loss: 7.7826\n",
      "Epoch 108/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.8806 - val_loss: 7.7635\n",
      "Epoch 109/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.8446 - val_loss: 7.7440\n",
      "Epoch 110/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.8094 - val_loss: 7.7253\n",
      "Epoch 111/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.7752 - val_loss: 7.7073\n",
      "Epoch 112/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.7416 - val_loss: 7.6912\n",
      "Epoch 113/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.7089 - val_loss: 7.6739\n",
      "Epoch 114/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6769 - val_loss: 7.6576\n",
      "Epoch 115/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6456 - val_loss: 7.6436\n",
      "Epoch 116/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.6150 - val_loss: 7.6288\n",
      "Epoch 117/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5854 - val_loss: 7.6158\n",
      "Epoch 118/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5561 - val_loss: 7.6016\n",
      "Epoch 119/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.5275 - val_loss: 7.5881\n",
      "Epoch 120/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4996 - val_loss: 7.5760\n",
      "Epoch 121/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4722 - val_loss: 7.5641\n",
      "Epoch 122/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4455 - val_loss: 7.5512\n",
      "Epoch 123/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.4193 - val_loss: 7.5392\n",
      "Epoch 124/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3938 - val_loss: 7.5289\n",
      "Epoch 125/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3688 - val_loss: 7.5164\n",
      "Epoch 126/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3443 - val_loss: 7.5064\n",
      "Epoch 127/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.3203 - val_loss: 7.4961\n",
      "Epoch 128/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2970 - val_loss: 7.4869\n",
      "Epoch 129/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2742 - val_loss: 7.4765\n",
      "Epoch 130/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2521 - val_loss: 7.4660\n",
      "Epoch 131/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2301 - val_loss: 7.4576\n",
      "Epoch 132/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.2090 - val_loss: 7.4483\n",
      "Epoch 133/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1881 - val_loss: 7.4406\n",
      "Epoch 134/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1682 - val_loss: 7.4311\n",
      "Epoch 135/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1484 - val_loss: 7.4232\n",
      "Epoch 136/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1294 - val_loss: 7.4157\n",
      "Epoch 137/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.1105 - val_loss: 7.4072\n",
      "Epoch 138/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0924 - val_loss: 7.4001\n",
      "Epoch 139/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0744 - val_loss: 7.3934\n",
      "Epoch 140/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0571 - val_loss: 7.3859\n",
      "Epoch 141/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0401 - val_loss: 7.3785\n",
      "Epoch 142/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0231 - val_loss: 7.3718\n",
      "Epoch 143/400\n",
      "6211/6211 [==============================] - 0s - loss: 1.0069 - val_loss: 7.3659\n",
      "Epoch 144/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9911 - val_loss: 7.3592\n",
      "Epoch 145/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9754 - val_loss: 7.3535\n",
      "Epoch 146/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9604 - val_loss: 7.3478\n",
      "Epoch 147/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9456 - val_loss: 7.3424\n",
      "Epoch 148/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9315 - val_loss: 7.3381\n",
      "Epoch 149/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9172 - val_loss: 7.3314\n",
      "Epoch 150/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.9035 - val_loss: 7.3285\n",
      "Epoch 151/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8899 - val_loss: 7.3229\n",
      "Epoch 152/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8767 - val_loss: 7.3199\n",
      "Epoch 153/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8638 - val_loss: 7.3151\n",
      "Epoch 154/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8513 - val_loss: 7.3108\n",
      "Epoch 155/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8391 - val_loss: 7.3062\n",
      "Epoch 156/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8270 - val_loss: 7.3031\n",
      "Epoch 157/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8149 - val_loss: 7.2992\n",
      "Epoch 158/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.8037 - val_loss: 7.2954\n",
      "Epoch 159/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7923 - val_loss: 7.2919\n",
      "Epoch 160/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7814 - val_loss: 7.2887\n",
      "Epoch 161/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7707 - val_loss: 7.2848\n",
      "Epoch 162/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7601 - val_loss: 7.2835\n",
      "Epoch 163/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7500 - val_loss: 7.2811\n",
      "Epoch 164/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7401 - val_loss: 7.2783\n",
      "Epoch 165/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7304 - val_loss: 7.2750\n",
      "Epoch 166/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7209 - val_loss: 7.2719\n",
      "Epoch 167/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7114 - val_loss: 7.2692\n",
      "Epoch 168/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.7021 - val_loss: 7.2690\n",
      "Epoch 169/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6934 - val_loss: 7.2649\n",
      "Epoch 170/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6846 - val_loss: 7.2637\n",
      "Epoch 171/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6762 - val_loss: 7.2604\n",
      "Epoch 172/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6677 - val_loss: 7.2590\n",
      "Epoch 173/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6596 - val_loss: 7.2562\n",
      "Epoch 174/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6516 - val_loss: 7.2544\n",
      "Epoch 175/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6436 - val_loss: 7.2535\n",
      "Epoch 176/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6362 - val_loss: 7.2518\n",
      "Epoch 177/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6285 - val_loss: 7.2493\n",
      "Epoch 178/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6211 - val_loss: 7.2484\n",
      "Epoch 179/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6140 - val_loss: 7.2454\n",
      "Epoch 180/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6070 - val_loss: 7.2439\n",
      "Epoch 181/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.6002 - val_loss: 7.2419\n",
      "Epoch 182/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5936 - val_loss: 7.2403\n",
      "Epoch 183/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5871 - val_loss: 7.2401\n",
      "Epoch 184/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5806 - val_loss: 7.2380\n",
      "Epoch 185/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5743 - val_loss: 7.2364\n",
      "Epoch 186/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5681 - val_loss: 7.2356\n",
      "Epoch 187/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5621 - val_loss: 7.2344\n",
      "Epoch 188/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5563 - val_loss: 7.2335\n",
      "Epoch 189/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5505 - val_loss: 7.2325\n",
      "Epoch 190/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5448 - val_loss: 7.2321\n",
      "Epoch 191/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5391 - val_loss: 7.2320\n",
      "Epoch 192/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5337 - val_loss: 7.2301\n",
      "Epoch 193/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5283 - val_loss: 7.2286\n",
      "Epoch 194/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5232 - val_loss: 7.2280\n",
      "Epoch 195/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5179 - val_loss: 7.2282\n",
      "Epoch 196/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5129 - val_loss: 7.2280\n",
      "Epoch 197/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5080 - val_loss: 7.2272\n",
      "Epoch 198/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.5030 - val_loss: 7.2267\n",
      "Epoch 199/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4986 - val_loss: 7.2271\n",
      "Epoch 200/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4939 - val_loss: 7.2267\n",
      "Epoch 201/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4892 - val_loss: 7.2259\n",
      "Epoch 202/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4847 - val_loss: 7.2269\n",
      "Epoch 203/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4802 - val_loss: 7.2251\n",
      "Epoch 204/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4759 - val_loss: 7.2263\n",
      "Epoch 205/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4716 - val_loss: 7.2249\n",
      "Epoch 206/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4675 - val_loss: 7.2265\n",
      "Epoch 207/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4636 - val_loss: 7.2256\n",
      "Epoch 208/400\n",
      "6211/6211 [==============================] - 0s - loss: 0.4593 - val_loss: 7.2265\n",
      " 32/691 [>.............................] - ETA: 0sTrain on 6212 samples, validate on 690 samples\n",
      "Epoch 1/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0938 - val_loss: 17.9689\n",
      "Epoch 2/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0869 - val_loss: 17.9683\n",
      "Epoch 3/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0777 - val_loss: 17.9654\n",
      "Epoch 4/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0623 - val_loss: 17.9581\n",
      "Epoch 5/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0376 - val_loss: 17.9432\n",
      "Epoch 6/400\n",
      "6212/6212 [==============================] - 0s - loss: 18.0009 - val_loss: 17.9187\n",
      "Epoch 7/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.9493 - val_loss: 17.8821\n",
      "Epoch 8/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.8821 - val_loss: 17.8334\n",
      "Epoch 9/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.7981 - val_loss: 17.7715\n",
      "Epoch 10/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.6953 - val_loss: 17.6946\n",
      "Epoch 11/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.5737 - val_loss: 17.6040\n",
      "Epoch 12/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.4320 - val_loss: 17.4963\n",
      "Epoch 13/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.2711 - val_loss: 17.3755\n",
      "Epoch 14/400\n",
      "6212/6212 [==============================] - 0s - loss: 17.0899 - val_loss: 17.2385\n",
      "Epoch 15/400\n",
      "6212/6212 [==============================] - 0s - loss: 16.8880 - val_loss: 17.0849\n",
      "Epoch 16/400\n",
      "6212/6212 [==============================] - 0s - loss: 16.6672 - val_loss: 16.9173\n",
      "Epoch 17/400\n",
      "6212/6212 [==============================] - 0s - loss: 16.4291 - val_loss: 16.7386\n",
      "Epoch 18/400\n",
      "6212/6212 [==============================] - 0s - loss: 16.1818 - val_loss: 16.5531\n",
      "Epoch 19/400\n",
      "6212/6212 [==============================] - 0s - loss: 15.9194 - val_loss: 16.3502\n",
      "Epoch 20/400\n",
      "6212/6212 [==============================] - 0s - loss: 15.6352 - val_loss: 16.1332\n",
      "Epoch 21/400\n",
      "6212/6212 [==============================] - 0s - loss: 15.3320 - val_loss: 15.9009\n",
      "Epoch 22/400\n",
      "6212/6212 [==============================] - 0s - loss: 15.0096 - val_loss: 15.6537\n",
      "Epoch 23/400\n",
      "6212/6212 [==============================] - 0s - loss: 14.6683 - val_loss: 15.3971\n",
      "Epoch 24/400\n",
      "6212/6212 [==============================] - 0s - loss: 14.3128 - val_loss: 15.1314\n",
      "Epoch 25/400\n",
      "6212/6212 [==============================] - 0s - loss: 13.9497 - val_loss: 14.8634\n",
      "Epoch 26/400\n",
      "6212/6212 [==============================] - 0s - loss: 13.5870 - val_loss: 14.5996\n",
      "Epoch 27/400\n",
      "6212/6212 [==============================] - 0s - loss: 13.2264 - val_loss: 14.3412\n",
      "Epoch 28/400\n",
      "6212/6212 [==============================] - 0s - loss: 12.8671 - val_loss: 14.0904\n",
      "Epoch 29/400\n",
      "6212/6212 [==============================] - 0s - loss: 12.5131 - val_loss: 13.8412\n",
      "Epoch 30/400\n",
      "6212/6212 [==============================] - 0s - loss: 12.1660 - val_loss: 13.6017\n",
      "Epoch 31/400\n",
      "6212/6212 [==============================] - 0s - loss: 11.8245 - val_loss: 13.3718\n",
      "Epoch 32/400\n",
      "6212/6212 [==============================] - 0s - loss: 11.4901 - val_loss: 13.1488\n",
      "Epoch 33/400\n",
      "6212/6212 [==============================] - 0s - loss: 11.1650 - val_loss: 12.9322\n",
      "Epoch 34/400\n",
      "6212/6212 [==============================] - 0s - loss: 10.8473 - val_loss: 12.7243\n",
      "Epoch 35/400\n",
      "6212/6212 [==============================] - 0s - loss: 10.5372 - val_loss: 12.5215\n",
      "Epoch 36/400\n",
      "6212/6212 [==============================] - 0s - loss: 10.2400 - val_loss: 12.3238\n",
      "Epoch 37/400\n",
      "6212/6212 [==============================] - 0s - loss: 9.9519 - val_loss: 12.1318\n",
      "Epoch 38/400\n",
      "6212/6212 [==============================] - 0s - loss: 9.6727 - val_loss: 11.9483\n",
      "Epoch 39/400\n",
      "6212/6212 [==============================] - 0s - loss: 9.4044 - val_loss: 11.7744\n",
      "Epoch 40/400\n",
      "6212/6212 [==============================] - 0s - loss: 9.1469 - val_loss: 11.6101\n",
      "Epoch 41/400\n",
      "6212/6212 [==============================] - 0s - loss: 8.9006 - val_loss: 11.4512\n",
      "Epoch 42/400\n",
      "6212/6212 [==============================] - 0s - loss: 8.6607 - val_loss: 11.2983\n",
      "Epoch 43/400\n",
      "6212/6212 [==============================] - 0s - loss: 8.4278 - val_loss: 11.1520\n",
      "Epoch 44/400\n",
      "6212/6212 [==============================] - 0s - loss: 8.2031 - val_loss: 11.0108\n",
      "Epoch 45/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.9848 - val_loss: 10.8766\n",
      "Epoch 46/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.7747 - val_loss: 10.7464\n",
      "Epoch 47/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.5718 - val_loss: 10.6215\n",
      "Epoch 48/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.3754 - val_loss: 10.5010\n",
      "Epoch 49/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.1867 - val_loss: 10.3847\n",
      "Epoch 50/400\n",
      "6212/6212 [==============================] - 0s - loss: 7.0050 - val_loss: 10.2708\n",
      "Epoch 51/400\n",
      "6212/6212 [==============================] - 0s - loss: 6.8294 - val_loss: 10.1626\n",
      "Epoch 52/400\n",
      "6212/6212 [==============================] - 0s - loss: 6.6596 - val_loss: 10.0573\n",
      "Epoch 53/400\n",
      "2528/6212 [===========>..................] - ETA: 0s - loss: 6.6331"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cb4bd412519b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCFModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_userid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_placeid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adamax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUSERS_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPLACES_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRATINGS_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUSERS_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPLACES_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRATINGS_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mmodel_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUSERS_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPLACES_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRATINGS_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1943\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaehun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "#train 과 test를 나눈다.\n",
    "#이후 train에서 validation split까지 해준후, overfitt 방지를 위해 callback을 걸어둠.\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import load_model\n",
    "n_split = 10\n",
    "best_model = None\n",
    "error = None\n",
    "for train_index,test_index in KFold(n_split).split(users):\n",
    "    users_train,users_test= users[train_index], users[test_index]\n",
    "    places_train,places_test = places[train_index], places[test_index]\n",
    "    ratings_train,ratings_test = ratings[train_index],ratings[test_index]\n",
    "    \n",
    "    model = DLmodel(2518, 410, 10)\n",
    "    model.compile(loss='mse', optimizer='adamax')\n",
    "    model.fit([users_train, places_train], ratings_train, nb_epoch=400, \n",
    "              validation_data = ([users_test, places_test], ratings_test), \n",
    "              callbacks = callbacks)\n",
    "    model_error = model.evaluate([users_test, places_test], ratings_test)\n",
    "    \n",
    "# history = model.fit([USERS, PLACES], RATINGS, nb_epoch=100, validation_split=.1, verbose=2, callbacks=callbacks)\n",
    "#model은 array 두개를 받아야 함(USERS, RATINGS)\n",
    "#데이터셋이 적어서 전체 데이터셋을 학습하고 싶은데, validation set을 나누지 않으면, overfit방지 earlystop을 할수 없으므로, \n",
    "#overfit직전 까지 학습하기 위한 최적의 epoch수를 찾기위해 kfold 통해 찾기(평균)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/220\n",
      "6902/6902 [==============================] - 0s - loss: 18.0809     \n",
      "Epoch 2/220\n",
      "6902/6902 [==============================] - 0s - loss: 18.0743     \n",
      "Epoch 3/220\n",
      "6902/6902 [==============================] - 0s - loss: 18.0649     \n",
      "Epoch 4/220\n",
      "6902/6902 [==============================] - 0s - loss: 18.0480     \n",
      "Epoch 5/220\n",
      "6902/6902 [==============================] - 0s - loss: 18.0185     \n",
      "Epoch 6/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.9721     \n",
      "Epoch 7/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.9062     \n",
      "Epoch 8/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.8177     \n",
      "Epoch 9/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.7043     \n",
      "Epoch 10/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.5659     \n",
      "Epoch 11/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.4009     \n",
      "Epoch 12/220\n",
      "6902/6902 [==============================] - 0s - loss: 17.2073     \n",
      "Epoch 13/220\n",
      "6902/6902 [==============================] - 0s - loss: 16.9871     \n",
      "Epoch 14/220\n",
      "6902/6902 [==============================] - 0s - loss: 16.7409     \n",
      "Epoch 15/220\n",
      "6902/6902 [==============================] - 0s - loss: 16.4660     \n",
      "Epoch 16/220\n",
      "6902/6902 [==============================] - 0s - loss: 16.1679     \n",
      "Epoch 17/220\n",
      "6902/6902 [==============================] - 0s - loss: 15.8442     \n",
      "Epoch 18/220\n",
      "6902/6902 [==============================] - 0s - loss: 15.4979     \n",
      "Epoch 19/220\n",
      "6902/6902 [==============================] - 0s - loss: 15.1327     \n",
      "Epoch 20/220\n",
      "6902/6902 [==============================] - 0s - loss: 14.7474     \n",
      "Epoch 21/220\n",
      "6902/6902 [==============================] - 0s - loss: 14.3436     \n",
      "Epoch 22/220\n",
      "6902/6902 [==============================] - 0s - loss: 13.9294     \n",
      "Epoch 23/220\n",
      "6902/6902 [==============================] - 0s - loss: 13.5105     \n",
      "Epoch 24/220\n",
      "6902/6902 [==============================] - 0s - loss: 13.0949     \n",
      "Epoch 25/220\n",
      "6902/6902 [==============================] - 0s - loss: 12.6888     \n",
      "Epoch 26/220\n",
      "6902/6902 [==============================] - 0s - loss: 12.2997     \n",
      "Epoch 27/220\n",
      "6902/6902 [==============================] - 0s - loss: 11.9193     \n",
      "Epoch 28/220\n",
      "6902/6902 [==============================] - 0s - loss: 11.5552     \n",
      "Epoch 29/220\n",
      "6902/6902 [==============================] - 0s - loss: 11.2066     \n",
      "Epoch 30/220\n",
      "6902/6902 [==============================] - 0s - loss: 10.8692     \n",
      "Epoch 31/220\n",
      "6902/6902 [==============================] - 0s - loss: 10.5425     \n",
      "Epoch 32/220\n",
      "6902/6902 [==============================] - 0s - loss: 10.2258     \n",
      "Epoch 33/220\n",
      "6902/6902 [==============================] - 0s - loss: 9.9276     \n",
      "Epoch 34/220\n",
      "6902/6902 [==============================] - 0s - loss: 9.6403     \n",
      "Epoch 35/220\n",
      "6902/6902 [==============================] - 0s - loss: 9.3613     \n",
      "Epoch 36/220\n",
      "6902/6902 [==============================] - 0s - loss: 9.0925     \n",
      "Epoch 37/220\n",
      "6902/6902 [==============================] - 0s - loss: 8.8383     \n",
      "Epoch 38/220\n",
      "6902/6902 [==============================] - 0s - loss: 8.5918     \n",
      "Epoch 39/220\n",
      "6902/6902 [==============================] - 0s - loss: 8.3535     \n",
      "Epoch 40/220\n",
      "6902/6902 [==============================] - 0s - loss: 8.1232     \n",
      "Epoch 41/220\n",
      "6902/6902 [==============================] - 0s - loss: 7.9003     \n",
      "Epoch 42/220\n",
      "6902/6902 [==============================] - 0s - loss: 7.6861     \n",
      "Epoch 43/220\n",
      "6902/6902 [==============================] - 0s - loss: 7.4810     \n",
      "Epoch 44/220\n",
      "6902/6902 [==============================] - 0s - loss: 7.2796     \n",
      "Epoch 45/220\n",
      "6902/6902 [==============================] - 0s - loss: 7.0843     \n",
      "Epoch 46/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.8960     \n",
      "Epoch 47/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.7144     \n",
      "Epoch 48/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.5398     \n",
      "Epoch 49/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.3702     \n",
      "Epoch 50/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.2055     \n",
      "Epoch 51/220\n",
      "6902/6902 [==============================] - 0s - loss: 6.0471     \n",
      "Epoch 52/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.8951     \n",
      "Epoch 53/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.7482     \n",
      "Epoch 54/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.6057     \n",
      "Epoch 55/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.4682     \n",
      "Epoch 56/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.3354     \n",
      "Epoch 57/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.2067     \n",
      "Epoch 58/220\n",
      "6902/6902 [==============================] - 0s - loss: 5.0813     \n",
      "Epoch 59/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.9601     \n",
      "Epoch 60/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.8421     \n",
      "Epoch 61/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.7285     \n",
      "Epoch 62/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.6184     \n",
      "Epoch 63/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.5112     \n",
      "Epoch 64/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.4072     \n",
      "Epoch 65/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.3071     \n",
      "Epoch 66/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.2095     \n",
      "Epoch 67/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.1140     \n",
      "Epoch 68/220\n",
      "6902/6902 [==============================] - 0s - loss: 4.0210     \n",
      "Epoch 69/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.9303     \n",
      "Epoch 70/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.8417     \n",
      "Epoch 71/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.7555     \n",
      "Epoch 72/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.6711     \n",
      "Epoch 73/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.5889     - ETA: 0s - loss: 3.59\n",
      "Epoch 74/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.5088     \n",
      "Epoch 75/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.4304     \n",
      "Epoch 76/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.3535     \n",
      "Epoch 77/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.2785     \n",
      "Epoch 78/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.2052     \n",
      "Epoch 79/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.1338     \n",
      "Epoch 80/220\n",
      "6902/6902 [==============================] - 0s - loss: 3.0642     \n",
      "Epoch 81/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.9962     \n",
      "Epoch 82/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.9299     \n",
      "Epoch 83/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.8649     \n",
      "Epoch 84/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.8021     \n",
      "Epoch 85/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.7406     \n",
      "Epoch 86/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.6806     \n",
      "Epoch 87/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.6218     \n",
      "Epoch 88/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.5643     \n",
      "Epoch 89/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.5087     \n",
      "Epoch 90/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.4545     \n",
      "Epoch 91/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.4016     \n",
      "Epoch 92/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.3496     \n",
      "Epoch 93/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.2993     \n",
      "Epoch 94/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.2500     \n",
      "Epoch 95/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.2022     \n",
      "Epoch 96/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.1559     \n",
      "Epoch 97/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.1106     \n",
      "Epoch 98/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.0667     \n",
      "Epoch 99/220\n",
      "6902/6902 [==============================] - 0s - loss: 2.0240     \n",
      "Epoch 100/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.9821     \n",
      "Epoch 101/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.9410     \n",
      "Epoch 102/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.9015     \n",
      "Epoch 103/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.8625     \n",
      "Epoch 104/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.8247     \n",
      "Epoch 105/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.7879     \n",
      "Epoch 106/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.7521     \n",
      "Epoch 107/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.7174     \n",
      "Epoch 108/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.6831     \n",
      "Epoch 109/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.6499     \n",
      "Epoch 110/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.6171     \n",
      "Epoch 111/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.5856     \n",
      "Epoch 112/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.5549     \n",
      "Epoch 113/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.5247     \n",
      "Epoch 114/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.4956     \n",
      "Epoch 115/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.4666     \n",
      "Epoch 116/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.4389     \n",
      "Epoch 117/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.4116     \n",
      "Epoch 118/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.3850     \n",
      "Epoch 119/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.3591     \n",
      "Epoch 120/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.3337     \n",
      "Epoch 121/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.3092     \n",
      "Epoch 122/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.2849     \n",
      "Epoch 123/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.2612     \n",
      "Epoch 124/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.2384     \n",
      "Epoch 125/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.2161     \n",
      "Epoch 126/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.1944     \n",
      "Epoch 127/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.1730     \n",
      "Epoch 128/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.1522     \n",
      "Epoch 129/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.1320     \n",
      "Epoch 130/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.1122     \n",
      "Epoch 131/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0929     \n",
      "Epoch 132/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0740     \n",
      "Epoch 133/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0556     \n",
      "Epoch 134/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0374     \n",
      "Epoch 135/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0199     \n",
      "Epoch 136/220\n",
      "6902/6902 [==============================] - 0s - loss: 1.0031     \n",
      "Epoch 137/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9864     \n",
      "Epoch 138/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9699     \n",
      "Epoch 139/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9542     \n",
      "Epoch 140/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9387     \n",
      "Epoch 141/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9236     \n",
      "Epoch 142/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.9091     \n",
      "Epoch 143/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8946     \n",
      "Epoch 144/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8805     \n",
      "Epoch 145/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8667     \n",
      "Epoch 146/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8534     \n",
      "Epoch 147/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8405     \n",
      "Epoch 148/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8275     \n",
      "Epoch 149/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8150     \n",
      "Epoch 150/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.8030     \n",
      "Epoch 151/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7911     \n",
      "Epoch 152/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7794     \n",
      "Epoch 153/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7681     \n",
      "Epoch 154/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7569     \n",
      "Epoch 155/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7462     \n",
      "Epoch 156/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7356     \n",
      "Epoch 157/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7254     \n",
      "Epoch 158/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7153     \n",
      "Epoch 159/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.7053     \n",
      "Epoch 160/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6958     \n",
      "Epoch 161/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6865     \n",
      "Epoch 162/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6770     \n",
      "Epoch 163/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6681     \n",
      "Epoch 164/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6593     \n",
      "Epoch 165/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6506     \n",
      "Epoch 166/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6421     \n",
      "Epoch 167/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6339     \n",
      "Epoch 168/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6258     \n",
      "Epoch 169/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6180     \n",
      "Epoch 170/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6103     \n",
      "Epoch 171/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.6026     \n",
      "Epoch 172/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5953     \n",
      "Epoch 173/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5880     \n",
      "Epoch 174/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5810     \n",
      "Epoch 175/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5742     \n",
      "Epoch 176/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5674     \n",
      "Epoch 177/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5607     \n",
      "Epoch 178/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5540     \n",
      "Epoch 179/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5480     \n",
      "Epoch 180/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5417     \n",
      "Epoch 181/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5356     \n",
      "Epoch 182/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5297     \n",
      "Epoch 183/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5240     \n",
      "Epoch 184/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5183     \n",
      "Epoch 185/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5127     \n",
      "Epoch 186/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5072     \n",
      "Epoch 187/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.5019     \n",
      "Epoch 188/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4966     \n",
      "Epoch 189/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4915     \n",
      "Epoch 190/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4863     \n",
      "Epoch 191/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4814     \n",
      "Epoch 192/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4765     \n",
      "Epoch 193/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4719     \n",
      "Epoch 194/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4670     \n",
      "Epoch 195/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4625     \n",
      "Epoch 196/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4581     \n",
      "Epoch 197/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4537     \n",
      "Epoch 198/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4494     \n",
      "Epoch 199/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4451     \n",
      "Epoch 200/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4409     \n",
      "Epoch 201/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6902/6902 [==============================] - 0s - loss: 0.4368     \n",
      "Epoch 202/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4327     \n",
      "Epoch 203/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4287     \n",
      "Epoch 204/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4248     \n",
      "Epoch 205/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4209     \n",
      "Epoch 206/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4172     \n",
      "Epoch 207/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4135     \n",
      "Epoch 208/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4099     \n",
      "Epoch 209/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4061     \n",
      "Epoch 210/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.4027     \n",
      "Epoch 211/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3993     \n",
      "Epoch 212/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3958     \n",
      "Epoch 213/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3924     \n",
      "Epoch 214/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3891     \n",
      "Epoch 215/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3859     \n",
      "Epoch 216/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3827     \n",
      "Epoch 217/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3794     \n",
      "Epoch 218/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3763     \n",
      "Epoch 219/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3733     \n",
      "Epoch 220/220\n",
      "6902/6902 [==============================] - 0s - loss: 0.3703     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d6cae7f48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlmodel = DLmodel(2518, 410,10)\n",
    "dlmodel.compile(loss='mse', optimizer='adamax')\n",
    "dlmodel.fit([users, places], ratings, nb_epoch=220)\n",
    "# 전체 데이터셋을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, place_id):\n",
    "    return MODEL.rate(user_id - 1, place_id - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛집</th>\n",
       "      <th>코드</th>\n",
       "      <th>place_id</th>\n",
       "      <th>닉네임</th>\n",
       "      <th>user_id</th>\n",
       "      <th>평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쭈불쭈불</td>\n",
       "      <td>Num=a_nam_0138</td>\n",
       "      <td>1</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>애기능생활관 학식</td>\n",
       "      <td>Num=a_nam_935</td>\n",
       "      <td>2</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>우승식당</td>\n",
       "      <td>Num=a_nam_787</td>\n",
       "      <td>4</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>고대맛집ㅋㅋ</td>\n",
       "      <td>Num=a_nam_0211</td>\n",
       "      <td>8</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>고른햇살</td>\n",
       "      <td>Num=a_nam_0002</td>\n",
       "      <td>9</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>트라타</td>\n",
       "      <td>Num=a_nam_740</td>\n",
       "      <td>82</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>프로마치</td>\n",
       "      <td>Num=a_nam_0040</td>\n",
       "      <td>83</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>학생회관 2층</td>\n",
       "      <td>Num=a_nam_766</td>\n",
       "      <td>84</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>학생회관 자율식당</td>\n",
       "      <td>Num=a_nam_916</td>\n",
       "      <td>85</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>한상차림밥상</td>\n",
       "      <td>Num=a_nam_785</td>\n",
       "      <td>86</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             맛집              코드  place_id   닉네임  user_id   평점\n",
       "4          쭈불쭈불  Num=a_nam_0138         1  검은여울        5  4.0\n",
       "27    애기능생활관 학식   Num=a_nam_935         2  검은여울        5  5.0\n",
       "150        우승식당   Num=a_nam_787         4  검은여울        5  4.0\n",
       "269      고대맛집ㅋㅋ  Num=a_nam_0211         8  검은여울        5  5.0\n",
       "335        고른햇살  Num=a_nam_0002         9  검은여울        5  4.0\n",
       "...         ...             ...       ...   ...      ...  ...\n",
       "3803        트라타   Num=a_nam_740        82  검은여울        5  4.0\n",
       "3837       프로마치  Num=a_nam_0040        83  검은여울        5  3.0\n",
       "3894    학생회관 2층   Num=a_nam_766        84  검은여울        5  4.0\n",
       "3910  학생회관 자율식당   Num=a_nam_916        85  검은여울        5  5.0\n",
       "3917     한상차림밥상   Num=a_nam_785        86  검은여울        5  4.0\n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user = ratings[ratings['user_id'] == 5][['맛집','코드', 'place_id', '닉네임','user_id', '평점']]\n",
    "random_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛집</th>\n",
       "      <th>코드</th>\n",
       "      <th>place_id</th>\n",
       "      <th>닉네임</th>\n",
       "      <th>user_id</th>\n",
       "      <th>평점</th>\n",
       "      <th>예상평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>부부 바지락 손칼국수</td>\n",
       "      <td>Num=a_nam_0314</td>\n",
       "      <td>32</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.990009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>이공김밥</td>\n",
       "      <td>Num=a_nam_605</td>\n",
       "      <td>71</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.537937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>밀플랜비 (Meal Plan B)</td>\n",
       "      <td>Num=a_nam_948</td>\n",
       "      <td>55</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.648077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>서브웨이 고려대점</td>\n",
       "      <td>Num=a_nam_0045</td>\n",
       "      <td>60</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.437020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>더멜팅</td>\n",
       "      <td>Num=a_nam_801</td>\n",
       "      <td>46</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.675076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>나정순할매쭈꾸미</td>\n",
       "      <td>Num=a_nam_845</td>\n",
       "      <td>44</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.105757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>안동반점</td>\n",
       "      <td>Num=a_nam_0370</td>\n",
       "      <td>64</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.459789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>야마토텐동</td>\n",
       "      <td>Num=a_nam_817</td>\n",
       "      <td>67</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.633264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>고고인디안쿠진 1호점</td>\n",
       "      <td>Num=a_nam_711</td>\n",
       "      <td>38</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.832880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>오월키친</td>\n",
       "      <td>Num=a_nam_996</td>\n",
       "      <td>69</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.827754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>¿¬¾îÀÌ¾ß±â</td>\n",
       "      <td>Num=a_nam_888</td>\n",
       "      <td>36</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.101974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>¹Ì½ºÅÍÄ«Ã÷</td>\n",
       "      <td>Num=a_nam_0372</td>\n",
       "      <td>35</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.048115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>붐바타</td>\n",
       "      <td>Num=a_nam_1021</td>\n",
       "      <td>33</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.877530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>미소초밥</td>\n",
       "      <td>Num=a_nam_1059</td>\n",
       "      <td>53</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.856143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>우정초밥</td>\n",
       "      <td>Num=a_nam_1123</td>\n",
       "      <td>70</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.311162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>애기능생활관 학식</td>\n",
       "      <td>Num=a_nam_935</td>\n",
       "      <td>2</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.813308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>평범식당</td>\n",
       "      <td>Num=a_nam_775</td>\n",
       "      <td>26</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.339962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>학생회관 자율식당</td>\n",
       "      <td>Num=a_nam_916</td>\n",
       "      <td>85</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.022263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>고대맛집ㅋㅋ</td>\n",
       "      <td>Num=a_nam_0211</td>\n",
       "      <td>8</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.585959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>백소정</td>\n",
       "      <td>Num=a_nam_981</td>\n",
       "      <td>14</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.835144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>카페 파우제 ( Kaffe Pause)</td>\n",
       "      <td>Num=a_nam_1087</td>\n",
       "      <td>81</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.733485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>고품콩</td>\n",
       "      <td>Num=a_nam_0356</td>\n",
       "      <td>10</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>트라타</td>\n",
       "      <td>Num=a_nam_740</td>\n",
       "      <td>82</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.444185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>미스터피자 고대점</td>\n",
       "      <td>Num=a_nam_0049</td>\n",
       "      <td>54</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.751586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>사랑마라탕</td>\n",
       "      <td>Num=a_nam_0357</td>\n",
       "      <td>58</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.648115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>학생회관 2층</td>\n",
       "      <td>Num=a_nam_766</td>\n",
       "      <td>84</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>스시바</td>\n",
       "      <td>Num=a_nam_0055</td>\n",
       "      <td>63</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.290652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>알래스카에서 온 연어가 맛있는 집</td>\n",
       "      <td>Num=a_nam_0268</td>\n",
       "      <td>66</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.552601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>안암역 3출 포장마차</td>\n",
       "      <td>Num=a_nam_1103</td>\n",
       "      <td>65</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.286319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>이공냉면</td>\n",
       "      <td>Num=a_nam_0179</td>\n",
       "      <td>72</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.246134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>오샬</td>\n",
       "      <td>Num=a_nam_0098</td>\n",
       "      <td>68</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.508526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>철남 (정대후문)</td>\n",
       "      <td>Num=a_nam_0113</td>\n",
       "      <td>80</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.072509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>찌개집</td>\n",
       "      <td>Num=a_nam_0009</td>\n",
       "      <td>79</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.235021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>짱가네 돈냉면</td>\n",
       "      <td>Num=a_nam_734</td>\n",
       "      <td>78</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.699264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>일미옥</td>\n",
       "      <td>Num=a_nam_0144</td>\n",
       "      <td>74</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.987303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>이이구</td>\n",
       "      <td>Num=a_nam_788</td>\n",
       "      <td>73</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.256859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쭈불쭈불</td>\n",
       "      <td>Num=a_nam_0138</td>\n",
       "      <td>1</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.526172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>무르무르드구스토</td>\n",
       "      <td>Num=a_nam_0043</td>\n",
       "      <td>51</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.197027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>모이리타</td>\n",
       "      <td>Num=a_nam_0044</td>\n",
       "      <td>31</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.426879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>곰이네국밥</td>\n",
       "      <td>Num=a_nam_735</td>\n",
       "      <td>41</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.366927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>우승식당</td>\n",
       "      <td>Num=a_nam_787</td>\n",
       "      <td>4</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.584639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>고른햇살</td>\n",
       "      <td>Num=a_nam_0002</td>\n",
       "      <td>9</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.126371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>미스터국밥</td>\n",
       "      <td>Num=a_nam_0005</td>\n",
       "      <td>13</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.602098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>서울쌈냉면 고대점</td>\n",
       "      <td>Num=a_nam_0120</td>\n",
       "      <td>16</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.309750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>어흥식당</td>\n",
       "      <td>Num=a_nam_829</td>\n",
       "      <td>18</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.135341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>영철버거</td>\n",
       "      <td>Num=a_nam_0041</td>\n",
       "      <td>19</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.255968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>용초수</td>\n",
       "      <td>Num=a_nam_0142</td>\n",
       "      <td>20</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.832135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>이세돈까스</td>\n",
       "      <td>Num=a_nam_0355</td>\n",
       "      <td>22</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.254516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>고래돈까스</td>\n",
       "      <td>Num=a_nam_0247</td>\n",
       "      <td>29</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.329306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>ÄÚÄÉÄÚÄÚ</td>\n",
       "      <td>Num=a_nam_0246</td>\n",
       "      <td>37</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.109061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>고고인디안쿠진 2호점</td>\n",
       "      <td>Num=a_nam_864</td>\n",
       "      <td>39</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.142559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>한상차림밥상</td>\n",
       "      <td>Num=a_nam_785</td>\n",
       "      <td>86</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.043592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>매스플레이트</td>\n",
       "      <td>Num=a_nam_0149</td>\n",
       "      <td>49</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.124034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>마카나이</td>\n",
       "      <td>Num=a_nam_808</td>\n",
       "      <td>48</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.614872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>주유소</td>\n",
       "      <td>Num=a_nam_0157</td>\n",
       "      <td>77</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.405606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>정상호프</td>\n",
       "      <td>Num=a_nam_0148</td>\n",
       "      <td>75</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.816760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>복근남자 한푼갈비찜</td>\n",
       "      <td>Num=a_nam_1068</td>\n",
       "      <td>56</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.015524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>프로마치</td>\n",
       "      <td>Num=a_nam_0040</td>\n",
       "      <td>83</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.035898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>마이셰프 (My Chef)</td>\n",
       "      <td>Num=a_nam_0375</td>\n",
       "      <td>47</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.050624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>정차돌</td>\n",
       "      <td>Num=a_nam_1141</td>\n",
       "      <td>76</td>\n",
       "      <td>검은여울</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.978894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         맛집              코드  place_id   닉네임  user_id   평점  \\\n",
       "2317            부부 바지락 손칼국수  Num=a_nam_0314        32  검은여울        5  5.0   \n",
       "3352                   이공김밥   Num=a_nam_605        71  검은여울        5  5.0   \n",
       "3023     밀플랜비 (Meal Plan B)   Num=a_nam_948        55  검은여울        5  5.0   \n",
       "3151              서브웨이 고려대점  Num=a_nam_0045        60  검은여울        5  5.0   \n",
       "2784                    더멜팅   Num=a_nam_801        46  검은여울        5  5.0   \n",
       "2762               나정순할매쭈꾸미   Num=a_nam_845        44  검은여울        5  5.0   \n",
       "3202                   안동반점  Num=a_nam_0370        64  검은여울        5  5.0   \n",
       "3223                  야마토텐동   Num=a_nam_817        67  검은여울        5  5.0   \n",
       "2564            고고인디안쿠진 1호점   Num=a_nam_711        38  검은여울        5  5.0   \n",
       "3328                   오월키친   Num=a_nam_996        69  검은여울        5  5.0   \n",
       "2441             ¿¬¾îÀÌ¾ß±â   Num=a_nam_888        36  검은여울        5  5.0   \n",
       "2375             ¹Ì½ºÅÍÄ«Ã÷  Num=a_nam_0372        35  검은여울        5  5.0   \n",
       "2329                    붐바타  Num=a_nam_1021        33  검은여울        5  5.0   \n",
       "2994                   미소초밥  Num=a_nam_1059        53  검은여울        5  5.0   \n",
       "3336                   우정초밥  Num=a_nam_1123        70  검은여울        5  5.0   \n",
       "27                애기능생활관 학식   Num=a_nam_935         2  검은여울        5  5.0   \n",
       "2117                   평범식당   Num=a_nam_775        26  검은여울        5  5.0   \n",
       "3910              학생회관 자율식당   Num=a_nam_916        85  검은여울        5  5.0   \n",
       "269                  고대맛집ㅋㅋ  Num=a_nam_0211         8  검은여울        5  5.0   \n",
       "1377                    백소정   Num=a_nam_981        14  검은여울        5  5.0   \n",
       "3801  카페 파우제 ( Kaffe Pause)  Num=a_nam_1087        81  검은여울        5  5.0   \n",
       "965                     고품콩  Num=a_nam_0356        10  검은여울        5  5.0   \n",
       "3803                    트라타   Num=a_nam_740        82  검은여울        5  4.0   \n",
       "3009              미스터피자 고대점  Num=a_nam_0049        54  검은여울        5  4.0   \n",
       "3110                  사랑마라탕  Num=a_nam_0357        58  검은여울        5  4.0   \n",
       "3894                학생회관 2층   Num=a_nam_766        84  검은여울        5  4.0   \n",
       "3192                    스시바  Num=a_nam_0055        63  검은여울        5  4.0   \n",
       "3215     알래스카에서 온 연어가 맛있는 집  Num=a_nam_0268        66  검은여울        5  4.0   \n",
       "3213            안암역 3출 포장마차  Num=a_nam_1103        65  검은여울        5  4.0   \n",
       "3419                   이공냉면  Num=a_nam_0179        72  검은여울        5  4.0   \n",
       "3283                     오샬  Num=a_nam_0098        68  검은여울        5  4.0   \n",
       "3780              철남 (정대후문)  Num=a_nam_0113        80  검은여울        5  4.0   \n",
       "3773                    찌개집  Num=a_nam_0009        79  검은여울        5  4.0   \n",
       "3701                짱가네 돈냉면   Num=a_nam_734        78  검은여울        5  4.0   \n",
       "3459                    일미옥  Num=a_nam_0144        74  검은여울        5  4.0   \n",
       "3441                    이이구   Num=a_nam_788        73  검은여울        5  4.0   \n",
       "4                      쭈불쭈불  Num=a_nam_0138         1  검은여울        5  4.0   \n",
       "2931               무르무르드구스토  Num=a_nam_0043        51  검은여울        5  4.0   \n",
       "2278                   모이리타  Num=a_nam_0044        31  검은여울        5  4.0   \n",
       "2658                  곰이네국밥   Num=a_nam_735        41  검은여울        5  4.0   \n",
       "150                    우승식당   Num=a_nam_787         4  검은여울        5  4.0   \n",
       "335                    고른햇살  Num=a_nam_0002         9  검은여울        5  4.0   \n",
       "1262                  미스터국밥  Num=a_nam_0005        13  검은여울        5  4.0   \n",
       "1460              서울쌈냉면 고대점  Num=a_nam_0120        16  검은여울        5  4.0   \n",
       "1511                   어흥식당   Num=a_nam_829        18  검은여울        5  4.0   \n",
       "1663                   영철버거  Num=a_nam_0041        19  검은여울        5  4.0   \n",
       "1853                    용초수  Num=a_nam_0142        20  검은여울        5  4.0   \n",
       "1964                  이세돈까스  Num=a_nam_0355        22  검은여울        5  4.0   \n",
       "2180                  고래돈까스  Num=a_nam_0247        29  검은여울        5  4.0   \n",
       "2510               ÄÚÄÉÄÚÄÚ  Num=a_nam_0246        37  검은여울        5  4.0   \n",
       "2612            고고인디안쿠진 2호점   Num=a_nam_864        39  검은여울        5  4.0   \n",
       "3917                 한상차림밥상   Num=a_nam_785        86  검은여울        5  4.0   \n",
       "2880                 매스플레이트  Num=a_nam_0149        49  검은여울        5  4.0   \n",
       "2847                   마카나이   Num=a_nam_808        48  검은여울        5  4.0   \n",
       "3556                    주유소  Num=a_nam_0157        77  검은여울        5  3.0   \n",
       "3514                   정상호프  Num=a_nam_0148        75  검은여울        5  3.0   \n",
       "3075             복근남자 한푼갈비찜  Num=a_nam_1068        56  검은여울        5  3.0   \n",
       "3837                   프로마치  Num=a_nam_0040        83  검은여울        5  3.0   \n",
       "2819         마이셰프 (My Chef)  Num=a_nam_0375        47  검은여울        5  3.0   \n",
       "3553                    정차돌  Num=a_nam_1141        76  검은여울        5  3.0   \n",
       "\n",
       "          예상평점  \n",
       "2317  3.990009  \n",
       "3352  4.537937  \n",
       "3023  4.648077  \n",
       "3151  3.437020  \n",
       "2784  4.675076  \n",
       "2762  5.105757  \n",
       "3202  4.459789  \n",
       "3223  3.633264  \n",
       "2564  4.832880  \n",
       "3328  4.827754  \n",
       "2441  5.101974  \n",
       "2375  4.048115  \n",
       "2329  4.877530  \n",
       "2994  3.856143  \n",
       "3336  5.311162  \n",
       "27    3.813308  \n",
       "2117  4.339962  \n",
       "3910  5.022263  \n",
       "269   4.585959  \n",
       "1377  3.835144  \n",
       "3801  2.733485  \n",
       "965   4.004524  \n",
       "3803  4.444185  \n",
       "3009  4.751586  \n",
       "3110  3.648115  \n",
       "3894  3.833214  \n",
       "3192  4.290652  \n",
       "3215  4.552601  \n",
       "3213  3.286319  \n",
       "3419  4.246134  \n",
       "3283  3.508526  \n",
       "3780  4.072509  \n",
       "3773  4.235021  \n",
       "3701  3.699264  \n",
       "3459  2.987303  \n",
       "3441  3.256859  \n",
       "4     4.526172  \n",
       "2931  3.197027  \n",
       "2278  4.426879  \n",
       "2658  4.366927  \n",
       "150   4.584639  \n",
       "335   4.126371  \n",
       "1262  3.602098  \n",
       "1460  3.309750  \n",
       "1511  4.135341  \n",
       "1663  4.255968  \n",
       "1853  3.832135  \n",
       "1964  4.254516  \n",
       "2180  4.329306  \n",
       "2510  4.109061  \n",
       "2612  4.142559  \n",
       "3917  4.043592  \n",
       "2880  4.124034  \n",
       "2847  3.614872  \n",
       "3556  3.405606  \n",
       "3514  3.816760  \n",
       "3075  4.015524  \n",
       "3837  3.035898  \n",
       "2819  4.050624  \n",
       "3553  2.978894  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user['예상평점'] = random_user.apply(lambda x: predict_rating(5, x['place_id']), axis=1)\n",
    "random_user.sort_values(by='평점', ascending=False).head(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>맛집</th>\n",
       "      <th>예상평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>183</td>\n",
       "      <td>남이네 분식</td>\n",
       "      <td>5.518865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>106</td>\n",
       "      <td>원진노기순 청국장</td>\n",
       "      <td>5.488256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>240</td>\n",
       "      <td>동네</td>\n",
       "      <td>5.344956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>154</td>\n",
       "      <td>특별식당</td>\n",
       "      <td>5.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>178</td>\n",
       "      <td>교우회관 학생식당</td>\n",
       "      <td>5.277291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>138</td>\n",
       "      <td>야순네 식당</td>\n",
       "      <td>5.245344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>173</td>\n",
       "      <td>우리동네만두가게</td>\n",
       "      <td>5.183782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>151</td>\n",
       "      <td>참새방앗간</td>\n",
       "      <td>5.172176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>199</td>\n",
       "      <td>프릭타이</td>\n",
       "      <td>5.113809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>148</td>\n",
       "      <td>제기돈</td>\n",
       "      <td>5.056477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>144</td>\n",
       "      <td>이수영피자</td>\n",
       "      <td>5.005250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>34</td>\n",
       "      <td>이츠 스테이크</td>\n",
       "      <td>4.955360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>117</td>\n",
       "      <td>곽씨아저씨</td>\n",
       "      <td>4.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>132</td>\n",
       "      <td>샌디앤샐리 (sandy&amp;sally)</td>\n",
       "      <td>4.944734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>197</td>\n",
       "      <td>킹수제만두</td>\n",
       "      <td>4.926526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>145</td>\n",
       "      <td>자스민</td>\n",
       "      <td>4.920021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>131</td>\n",
       "      <td>비나 레스토랑 정문</td>\n",
       "      <td>4.915309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>118</td>\n",
       "      <td>국수랑</td>\n",
       "      <td>4.873463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>115</td>\n",
       "      <td>경성고기꾼</td>\n",
       "      <td>4.845160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>120</td>\n",
       "      <td>국시랑</td>\n",
       "      <td>4.838117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      place_id                   맛집      예상평점\n",
       "5469       183               남이네 분식  5.518865\n",
       "4215       106            원진노기순 청국장  5.488256\n",
       "6088       240                   동네  5.344956\n",
       "5010       154                 특별식당  5.325227\n",
       "5406       178            교우회관 학생식당  5.277291\n",
       "4787       138               야순네 식당  5.245344\n",
       "5320       173             우리동네만두가게  5.183782\n",
       "4941       151                참새방앗간  5.172176\n",
       "5661       199                 프릭타이  5.113809\n",
       "4906       148                  제기돈  5.056477\n",
       "4853       144                이수영피자  5.005250\n",
       "2353        34              이츠 스테이크  4.955360\n",
       "4381       117                곽씨아저씨  4.951594\n",
       "4656       132  샌디앤샐리 (sandy&sally)  4.944734\n",
       "5642       197                킹수제만두  4.926526\n",
       "4877       145                  자스민  4.920021\n",
       "4573       131           비나 레스토랑 정문  4.915309\n",
       "4389       118                  국수랑  4.873463\n",
       "4354       115                경성고기꾼  4.845160\n",
       "4426       120                  국시랑  4.838117"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = ratings[ratings['place_id'].isin(random_user['place_id']) == False][['place_id', '맛집']].drop_duplicates()\n",
    "recommendations['예상평점'] = recommendations.apply(lambda x: predict_rating(8, x['place_id']), axis=1)\n",
    "recommendations.sort_values(by='예상평점', ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
